{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bdY0f3U9Haf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uuelBSb1xnI"
      },
      "source": [
        "df = pd.read_csv('sample_data/mnist_train_small.csv',header = None)\n",
        "X_train = np.array(df.iloc[:,1:])\n",
        "y_train = np.array(df.iloc[:,0:1])\n",
        "df1 = pd.read_csv('sample_data/mnist_test.csv',header = None)\n",
        "X_test = np.array(df.iloc[:,1:])\n",
        "y_test = np.array(df.iloc[:,0:1])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyfm-0No1wwh"
      },
      "source": [
        "class logistic_regression:\n",
        "  def __init__(self, alpha=0.05, lam=0.01, num_iters=5):\n",
        "    self.alpha = alpha\n",
        "    self.lam = lam\n",
        "    self.num_iters = num_iters\n",
        "  \n",
        "  def sigmoid(self, z):\n",
        "    return 1/(1 + np.exp(-1*z))\n",
        "\n",
        "  def normalize(self,X):\n",
        "    m, n = X.shape\n",
        "    for i in range(n):\n",
        "      X[:,i] = (X[:,i] - np.mean(X[:,i]))/(np.std(X[:,i]) + np.exp(-9))\n",
        "    X0 = np.ones((m,1))\n",
        "    X = np.hstack((X0,X))\n",
        "    return X\n",
        "\n",
        "  def hypothesis(self, X, theta):\n",
        "    h = (self.sigmoid(X@self.theta.T))\n",
        "    return h\n",
        "\n",
        "  def cost(self, X, y, theta):\n",
        "    m, n = X.shape\n",
        "    h = self.sigmoid(X@self.theta.T)\n",
        "    cost = (-1/m)*(np.sum(y*np.log(h + np.exp(-9)) + (1-y)*(np.log(1-h + np.exp(-9))))) + (self.lam/2*m)*(np.sum(self.theta[:,1:]**2))\n",
        "    return cost\n",
        "\n",
        "  def fit(self, X, y, n_cls):\n",
        "    X = self.normalize(X)\n",
        "    m, n = X.shape\n",
        "    self.n_cls = n_cls\n",
        "    y_cls = np.zeros((m,self.n_cls))\n",
        "    for i in range(m):\n",
        "      y_cls[i,y[i]] = 1\n",
        "\n",
        "    self.J_hist = []\n",
        "    self.iters = []\n",
        "        \n",
        "    self.theta = np.zeros((self.n_cls,n))\n",
        "\n",
        "    for i in range(self.num_iters):\n",
        "      theta_temp = self.theta\n",
        "      theta_temp[:,0:1] = 0\n",
        "      h = self.hypothesis(X,self.theta)\n",
        "      self.theta = self.theta - (self.alpha/m)*((h-y_cls).T@X + (self.lam*theta_temp))\n",
        "      self.J_hist.append(self.cost(X,y_cls,self.theta))\n",
        "      print(self.cost(X,y_cls,self.theta))\n",
        "      self.iters.append(i)\n",
        "      print(i)\n",
        "\n",
        "  def plot(self):\n",
        "    plt.plot(self.iters,self.J_hist)\n",
        "    plt.xlabel(\"Number Of Iterations\")\n",
        "    plt.ylabel(\"Cost Function\")\n",
        "    plt.title(\"Cost Function vs Iteration\")\n",
        "\n",
        "  def predict(self,X):\n",
        "    X = self.normalize(X)\n",
        "    y_pred = self.hypothesis(X,self.theta)\n",
        "    y_pred = np.argmax(y_pred, axis=1).reshape(len(y_pred),1)\n",
        "    return y_pred\n",
        "\n",
        "  def predict_prob(self,X):\n",
        "    X = self.normalize(X)\n",
        "    y_pred_prob = self.hypothesis(X,self.theta)\n",
        "    return y_pred_prob\n",
        "\n",
        "  def accuracy(self,y,y_pred):\n",
        "    m = len(y_test)\n",
        "    return (np.mean(y==y_pred))*100\n",
        "\n",
        "  def score(self, y, y_pred):\n",
        "    ''' 'score' method takes y, y_pred as arguments.\n",
        "    Calculates the y_mean and R2 score(Coefficient of determination), and returns R2 score'''\n",
        "    score = 1 - ((y - y_pred)**2).sum()/((y - y.mean())**2).sum()\n",
        "    return score  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0coPVgte1jly"
      },
      "source": [
        "a = logistic_regression()\n",
        "a.fit(X_train,y_train,10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5w0IAGPW48d"
      },
      "source": [
        "a.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VcGbc2eu775"
      },
      "source": [
        "y_pred = a.predict(X_train)\n",
        "print(\"learn Train Accuracy: \",a.accuracy(y_train,y_pred))\n",
        "y_pred = a.predict(X_test)\n",
        "print(\"learn Test Accuracy\",a.accuracy(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMiOv51DS4H0"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "sk = LogisticRegression()\n",
        "sk.fit(X_train,y_train)\n",
        "y_pred = sk.predict(X_train)\n",
        "print(\"sk-learn Train Accuracy: \",a.accuracy(y_train,y_pred))\n",
        "y_pred = sk.predict(X_test)\n",
        "print(\"sk-learn Test Accuracy\",a.accuracy(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}